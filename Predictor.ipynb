{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_data = pd.read_csv('cluster_map.csv', sep=',')\n",
    "order_data = pd.read_csv('order.txt', sep='\\t')\n",
    "weather_data = pd.read_csv('weather_merged.txt', sep='\\t')\n",
    "\n",
    "order_data.columns = ['Order_id', 'driver_id', 'passenger_id', 'start_region', 'dest_region', 'price', 'time']\n",
    "region_data.columns = ['region_hash', 'region_id']\n",
    "weather_data.columns = ['time', 'weather', 'temperature', 'pm2.5']\n",
    "\n",
    "order_data['time'] = pd.to_datetime(order_data['time'])\n",
    "\n",
    "weather_data['weather'].astype(int)\n",
    "weather_data['temperature'].astype(int)\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "\n",
    "line = []\n",
    "with open('poi_data.txt', 'r') as file:\n",
    "    for lines in file:\n",
    "        line.append(lines)\n",
    "poi_data = []\n",
    "for i in line:\n",
    "    splitted = i.split('\\t')\n",
    "    poi_data.append(splitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(s):\n",
    "    facilities = s.split()\n",
    "    facilities_dict = {}\n",
    "    for f in facilities:\n",
    "        parts = f.split('#')[1].split(':')\n",
    "        if len(parts) == 2:\n",
    "            cls, num = parts\n",
    "            facilities_dict[cls] = int(num)\n",
    "    \n",
    "    return np.sum([np.sqrt(num) for num in facilities_dict.values()])\n",
    "\n",
    "poi_dict = {}\n",
    "for i in range(len(poi_data)): \n",
    "    str1 = \"\"  \n",
    "    for j in range(1, len(poi_data[i])):\n",
    "        str1 += poi_data[i][j]\n",
    "    poi_dict[poi_data[i][0]] = metric(str1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding day coloumn to represent days from 1 - 21\n",
    "day_list = order_data['time'].dt.day\n",
    "order_data['day'] = day_list\n",
    "day_list = pd.Series([])\n",
    "\n",
    "weather_data['day'] = weather_data['time'].dt.day\n",
    "\n",
    "#sorting all data on time basis\n",
    "region_data.columns\n",
    "order_data= order_data.sort_values(by=('time'))\n",
    "\n",
    "def addTimeslot(order_data):\n",
    "    separated_dfs = []\n",
    "    for day in order_data['day'].unique():\n",
    "        day_df = order_data[order_data['day'] == day].reset_index(drop=True)\n",
    "        num_rows = day_df.shape[0]\n",
    "        time_slots = []\n",
    "        count = 1\n",
    "        for i in range(num_rows):\n",
    "            time_slots.append(count)\n",
    "            if (i+1) % (num_rows//144) == 0:\n",
    "                if (count < 144):\n",
    "                    count += 1\n",
    "        day_df['timeslot'] = time_slots\n",
    "        separated_dfs.append(day_df)\n",
    "\n",
    "    new_order_data = pd.concat(separated_dfs, ignore_index=True)\n",
    "    order_data = new_order_data\n",
    "    del new_order_data\n",
    "    return order_data\n",
    "\n",
    "order_data = addTimeslot(order_data)\n",
    "order_data_wo_nan = order_data.dropna(axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_data_test= pd.read_csv('test_cluster_map', sep='\\t')\n",
    "order_data_test = pd.read_csv('test_order.txt', sep=',')\n",
    "weather_data_test = pd.read_csv('test_weather.txt', sep='\\t')\n",
    "\n",
    "order_data_test.columns = ['order_id', 'driver_id', 'start_region', 'end_region', 'time']\n",
    "region_data_test.columns = ['region_hash', 'region_id']\n",
    "weather_data_test.columns = ['time', 'weather', 'temperature', 'pm2.5']\n",
    "\n",
    "order_data_test['time'] = pd.to_datetime(order_data_test['time'])\n",
    "\n",
    "weather_data_test['weather'].astype(int)\n",
    "weather_data_test['temperature'].astype(int)\n",
    "weather_data_test['time'] = pd.to_datetime(weather_data_test['time'])\n",
    "order_data_test = order_data_test.sort_values(by=('time'))\n",
    "\n",
    "day_list = order_data_test['time'].dt.day - 22\n",
    "order_data_test['day'] = day_list\n",
    "day_list = pd.Series([])\n",
    "\n",
    "weather_data_test['day'] = (weather_data_test['time'].dt.day - 22)\n",
    "\n",
    "order_data_test = addTimeslot(order_data_test)\n",
    "\n",
    "line_test = []\n",
    "with open('test_poi_data', 'r') as file:\n",
    "    for lines in file:\n",
    "        line.append(lines)\n",
    "poi_data_test = []\n",
    "for i in line:\n",
    "    splitted = i.split('\\t')\n",
    "    poi_data_test.append(splitted)\n",
    "\n",
    "poi_dict_test = {}\n",
    "for i in range(len(poi_data_test)): \n",
    "    str1 = \"\"  \n",
    "    for j in range(1, len(poi_data_test[i])):\n",
    "        str1 += poi_data_test[i][j]\n",
    "    poi_dict_test[poi_data_test[i][0]] = metric(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(order_data, weather_data, on='time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Model to predict temperature given a time slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE:  1.4827586206896552\n",
      "Decision Tree Regression MSE: 0.7106435083362084\n",
      "Random Forest Regression MSE: 0.6635034182009142\n",
      "Support Vector Regression MSE: 0.6450401465358189\n",
      "K-Nearest Neighbors Regression MSE: 0.7109242563841559\n"
     ]
    }
   ],
   "source": [
    "####################The model that predicts the weather given a timeslot \n",
    "\n",
    "time_slot_list = [] \n",
    "temperature_list = []\n",
    "\n",
    "for i in range(1, 145):\n",
    "    time_slot_list.append(i)\n",
    "    demand_per_slot = merge[merge['timeslot'] == i]\n",
    "    temp = demand_per_slot['temperature'].values\n",
    "    temperature_list.append(temp.mean())\n",
    "\n",
    "time_slot_list = np.reshape(time_slot_list, (-1, 1))\n",
    "temperature_list = np.reshape(temperature_list, (-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(time_slot_list, temperature_list, test_size=0.2, random_state=42)\n",
    "\n",
    "weatherModel = LinearRegression().fit(X_train, y_train)\n",
    "pred = weatherModel.predict(X_test)\n",
    "pred = [int(x) for x in pred]\n",
    "y_test = [int(x) for x in y_test]\n",
    "lrMSE = mean_squared_error(y_test, pred)\n",
    "\n",
    "# Train a decision tree regression model\n",
    "treeModel = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "treePred = treeModel.predict(X_test)\n",
    "treeMSE = mean_squared_error(y_test, treePred)\n",
    "\n",
    "# Train a random forest regression model\n",
    "forestModel = RandomForestRegressor().fit(X_train, y_train)\n",
    "forestPred = forestModel.predict(X_test)\n",
    "forestMSE = mean_squared_error(y_test, forestPred)\n",
    "\n",
    "# Train a support vector regression model\n",
    "svmModel = SVR().fit(X_train, y_train)\n",
    "svmPred = svmModel.predict(X_test)\n",
    "svmMSE = mean_squared_error(y_test, svmPred)\n",
    "\n",
    "# Train a k-nearest neighbors regression model\n",
    "knnModel = KNeighborsRegressor().fit(X_train, y_train)\n",
    "knnPred = knnModel.predict(X_test)\n",
    "knnMSE = mean_squared_error(y_test, knnPred)\n",
    "\n",
    "# Print the mean squared error for each model\n",
    "print('Linear Regression MSE: ', lrMSE)\n",
    "print('Decision Tree Regression MSE:', treeMSE)\n",
    "print('Random Forest Regression MSE:', forestMSE)\n",
    "print('Support Vector Regression MSE:', svmMSE)\n",
    "print('K-Nearest Neighbors Regression MSE:', knnMSE)\n",
    "\n",
    "models = {  weatherModel : lrMSE, \n",
    "            treeModel : treeMSE, \n",
    "            forestModel : forestMSE, \n",
    "            svmModel : svmMSE, \n",
    "            knnModel : knnMSE}\n",
    "\n",
    "WeatherModel = min(models, key=models.get)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a pred_weather list that contains the model predicted values for each timeslot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_weather = []\n",
    "for i in range(1, 145):\n",
    "    p = np.array([i])\n",
    "    p = np.reshape(p, (1, -1))\n",
    "    l = WeatherModel.predict(p)\n",
    "    pred_weather.append(l[0])\n",
    "for p in range(len(pred_weather)):\n",
    "    pred_weather[p] = int(pred_weather[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_nan = order_data[order_data.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionList = region_data['region_hash'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    " \n",
    "def create_feature_list_train(only_nan):\n",
    "    timeslot = []\n",
    "    region = []\n",
    "    weather = []\n",
    "    poi = []\n",
    "    gap = []\n",
    "    for i in range(1, 145):\n",
    "        per_timeSlot = only_nan[only_nan['timeslot'] == i]\n",
    "        for j in range(region_data.shape[0]):\n",
    "            region.append(region_data.iloc[j][0]) \n",
    "            poi.append(poi_dict[region_data.iloc[j][0]]) \n",
    "            timeslot.append(i) \n",
    "            weather.append(pred_weather[i - 1])   \n",
    "            temp = per_timeSlot[per_timeSlot['start_region'] == region_data.iloc[j][0]]\n",
    "            gap.append(temp.shape[0])\n",
    "    regionEncoded = le.fit_transform(region) \n",
    "    FeatureList = [[x,y,z, m] for x,y,z,m in zip(timeslot, regionEncoded, weather, poi)]\n",
    "    return FeatureList, gap\n",
    "\n",
    "def create_feature_list_teste(df):\n",
    "    timeslot = []\n",
    "    region = []\n",
    "    weather = []\n",
    "    poi = []\n",
    "\n",
    "    for i in range(1, 145):\n",
    "        per_timeSlot = df[df['timeslot'] == i]\n",
    "        for j in range(region_data.shape[0]):\n",
    "            region.append(region_data.iloc[j][0])\n",
    "            poi.append(poi_dict[region_data.iloc[j][0]])\n",
    "            timeslot.append(i)\n",
    "            weather.append(pred_weather[i - 1])\n",
    "            temp = per_timeSlot[per_timeSlot['start_region'] == region_data.iloc[j][0]]\n",
    "    regionEncoded = le.fit_transform(region)\n",
    "    FeatureList = [[x,y,z,m] for x,y,z,m in zip(timeslot, regionEncoded, weather, poi)]\n",
    "    return FeatureList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureList, gap = create_feature_list_train(only_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_Scaled = scaler.fit_transform(featureList)\n",
    "\n",
    "\n",
    "\n",
    "svrModel_final = SVR().fit(features_Scaled, gap)\n",
    "LinearRegression_final = LinearRegression().fit(featureList, gap)\n",
    "treeReg_final = DecisionTreeRegressor().fit(features_Scaled, gap)\n",
    "forest_final = RandomForestRegressor().fit(features_Scaled, gap)\n",
    "knn_final = KNeighborsRegressor().fit(features_Scaled, gap)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureList = create_feature_list_teste(order_data_test)\n",
    "gap_test = []\n",
    "for i in range(len(FeatureList)):\n",
    "    gap_test.append(0)\n",
    "\n",
    "SVR_predictions = svrModel_final.predict(FeatureList)\n",
    "LR_predictions = LinearRegression_final.predict(FeatureList)\n",
    "treeReg_predictions = treeReg_final.predict(FeatureList)\n",
    "forest_predictions = forest_final.predict(FeatureList)\n",
    "knn_predictions = knn_final.predict(FeatureList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE:  64.21383318344303\n",
      "Linear Regression MSE:  28001.759429059577\n",
      "Decision Tree Regression MSE: 255.97510683760683\n",
      "Random Forest Regression MSE: 2970.0351055448714\n",
      "K-Nearest Neighbors Regression MSE: 3817.751730769231\n"
     ]
    }
   ],
   "source": [
    "SVR_error = mean_squared_error(gap_test, SVR_predictions)\n",
    "LR_error = mean_squared_error(gap_test, LR_predictions)\n",
    "treeReg_error = mean_squared_error(gap_test, treeReg_predictions)\n",
    "forest_error = mean_squared_error(gap_test, forest_predictions)\n",
    "knn_error = mean_squared_error(gap_test, knn_predictions)\n",
    "\n",
    "print('SVR MSE: ', SVR_error)\n",
    "print('Linear Regression MSE: ', LR_error)  \n",
    "print('Decision Tree Regression MSE:', treeReg_error)\n",
    "print('Random Forest Regression MSE:', forest_error)\n",
    "print('K-Nearest Neighbors Regression MSE:', knn_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
